{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech MNIST\n",
    "We are operating on melspectrogram features. Due to the similarity with images, we can use a CNN to classify the spoken digits.\n",
    "\n",
    "For the data, we are going to use the following repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/jayrodge/AudioMNIST-using-PyTorch.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries\n",
    "First we are going to import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "os.chdir('AudioMNIST-using-PyTorch/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "We are going to load the data and preprocess it. Refer to the comment for each function for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(path):\n",
    "    '''\n",
    "    We are going to load png images and resize them to 224x224.\n",
    "    After that, we normalize the images to be in the range [-0.5, 0.5].\n",
    "    '''\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_png(image, channels=3)\n",
    "    image = tf.image.resize(image, [224, 224])\n",
    "    image = (image / 255.0) - 0.5\n",
    "    return image\n",
    "\n",
    "def get_filenames_and_labels(root_dir):\n",
    "    '''\n",
    "    Returns a list of filenames and a list of labels. The filenames and labels are matched.\n",
    "    - Subfolders under `AudioMNIST-using-PyTorch/MNIST/` corresponds to the labels.\n",
    "        - Eg. `AudioMNIST-using-PyTorch/MNIST/00/` contains all the files with label 0.\n",
    "    - Labels should be integers from 0 to 9.\n",
    "    '''\n",
    "    # TODO: Fill me\n",
    "    pass\n",
    "\n",
    "def split_data(filenames, labels, test_size=0.2, valid_size=0.2):\n",
    "    '''\n",
    "    We are going to split pairs of filenames and labels into train, test and valid sets.\n",
    "        - For example, if `test_size=0.2` and `valid_size=0.2`, then 60% of the data will be used for training,\n",
    "        and 20% each for testing and validation.\n",
    "    - Please refer to the documentation of `train_test_split` in `sklearn.model_selection` for more information.\n",
    "    - https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "    '''\n",
    "    # Split into train and temp (test + valid)\n",
    "    filenames_train, filenames_temp, labels_train, labels_temp = train_test_split(\n",
    "        filenames, labels, test_size=(test_size + valid_size), stratify=labels, random_state=42)\n",
    "    \n",
    "    # TODO: Split temp into test and valid\n",
    "    \n",
    "    return filenames_train, labels_train, filenames_test, labels_test, filenames_valid, labels_valid\n",
    "\n",
    "def create_dataset(filenames, labels, batch_size=32):\n",
    "    '''\n",
    "    This function creates a `tf.data.Dataset` from a list of filenames and a list of labels.\n",
    "    The function should work out of the box. You don't need to modify it.\n",
    "    '''\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "    dataset = dataset.map(lambda x, y: (load_and_preprocess_image(x), tf.cast(y, tf.int32)),\n",
    "                          num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.shuffle(buffer_size=len(filenames))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intantiation of Datasets\n",
    "Now we are actually going to call the preprocessing functions and instantiate the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = 'MNIST'\n",
    "batch_size = 128\n",
    "\n",
    "# Get filenames and labels\n",
    "filenames, labels = get_filenames_and_labels(root_dir)\n",
    "\n",
    "# TODO: Split data (One line of code)\n",
    "# You should use the function `split_data` that you have implemented.\n",
    "\n",
    "# TODO: Create datasets (Three lines of code)\n",
    "# You should use the function `create_dataset` that was provided.\n",
    "\n",
    "# Logging the dataset information along with the number of samples\n",
    "print(\"Train Dataset:\", train_dataset, \"Number of Samples:\", len(filenames_train))\n",
    "print(\"Test Dataset:\", test_dataset, \"Number of Samples:\", len(filenames_test))\n",
    "print(\"Validation Dataset:\", valid_dataset, \"Number of Samples:\", len(filenames_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "We can visualize the logmelspectrogram to see how it looks like.\n",
    "This block also makes sure that data preprocessing was done correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "classes = [str(i) for i in range(10)]  # If your classes are labeled 0 through 9\n",
    "# Function to un-normalize and display an image\n",
    "def imshow(img):\n",
    "    img = img * 0.5 + 0.5  # unnormalize\n",
    "    plt.imshow(img)  # No need to transpose\n",
    "\n",
    "# Obtain one batch of training images\n",
    "for images, labels in train_dataset.take(1):\n",
    "    images = images.numpy()  # Convert images to numpy for display\n",
    "    labels = labels.numpy()  # Convert labels to numpy for display\n",
    "\n",
    "# Plot the images in the batch, along with the corresponding labels\n",
    "fig = plt.figure(figsize=(25, 4))\n",
    "# Display 20 images\n",
    "for idx in np.arange(20):\n",
    "    ax = fig.add_subplot(2, 10, idx+1, xticks=[], yticks=[])\n",
    "    imshow(images[idx])\n",
    "    ax.set_title(classes[labels[idx]])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Model\n",
    "We are going to use a simple CNN model to classify the spoken digits.\n",
    "- Your are welcome to define your own model architecture.\n",
    "- The baseline approach is to translate the following model from PyTorch to TensorFlow.\n",
    "```python\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # convolutional layer\n",
    "        self.conv1 = nn.Conv2d(3, 16, 5)\n",
    "        # max pooling layer\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 5)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc1 = nn.Linear(32*53*53, 256)\n",
    "        self.fc2 = nn.Linear(256, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # add sequence of convolutional and max pooling layers\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(-1, 32 * 53 * 53)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.softmax(self.fc3(x))\n",
    "        return x\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(models.Model):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # TODO: fill me\n",
    "\n",
    "\n",
    "    def call(self, x):\n",
    "        # TODO: fill me\n",
    "        return x\n",
    "\n",
    "# Create the model instance\n",
    "model = Net()\n",
    "\n",
    "# Model summary to check the architecture\n",
    "model.build((None, 224, 224, 3))  # `None` can accommodate a variable batch size\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function and Optimizer\n",
    "One final step before we can simply call `model.fit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "loss_function = SparseCategoricalCrossentropy()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = SGD(learning_rate=0.001, momentum=0.9)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=loss_function,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train!\n",
    "Ideally the model should produce an Acc. of 96% or more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "n_epochs = 2  # You may increase this number, but 2 epochs works well enough\n",
    "\n",
    "# Callback for saving the best model in the TensorFlow SavedModel format\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint('model_MNIST', save_best_only=True, save_format=\"tf\")\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(train_dataset,\n",
    "                    validation_data=valid_dataset,\n",
    "                    epochs=n_epochs,\n",
    "                    callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Testing the CNN Model\n",
    " Evaluate the model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_dataset)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.6f}, Test Accuracy: {test_accuracy:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Point:\n",
    "- Try to report the acc of our model on different digits.\n",
    "- Try to report a confusion matrix."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hgf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
